{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Generate embeddings for catalog images"
      ],
      "metadata": {
        "id": "keBiL_XHl2yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_embeddings = []\n",
        "image_ids = []\n",
        "\n",
        "catalog_path = \"catalog_images\"\n",
        "\n",
        "for product_id in tqdm(os.listdir(catalog_path)):\n",
        "    product_dir = os.path.join(catalog_path, product_id)\n",
        "\n",
        "    if not os.path.isdir(product_dir):\n",
        "        continue\n",
        "\n",
        "    for image_name in os.listdir(product_dir):\n",
        "        image_path = os.path.join(product_dir, image_name)\n",
        "\n",
        "        try:\n",
        "            image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                embedding = model.encode_image(image).cpu().numpy().flatten()\n",
        "\n",
        "            image_embeddings.append(embedding)\n",
        "            image_ids.append((product_id, image_name))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error with {image_path}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIld8poYYYoP",
        "outputId": "4b99e304-8f1e-496d-d78b-41933c04b976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 969/969 [44:11<00:00,  2.74s/it]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
